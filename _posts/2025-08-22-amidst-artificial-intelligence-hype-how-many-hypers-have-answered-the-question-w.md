---
layout: post
title: "Amidst artificial intelligence hype, how many hypers have answered the question, 'what"
date: 2025-08-22
categories: [linkedin]
tags: [linkedin, social-media]
author: "Justin O'Brien"
excerpt: "Amidst artificial intelligence hype, how many hypers have answered the question, 'what exactly is \"intelligence\"?' Pop-philosopher and Silicon Valley icon, Nick Bostrom, certainly hasn't, in his decade-old book I revi..."
linkedin_url: "https://www.linkedin.com/feed/update/urn:li:activity:7364578338889228288"
---

*Originally posted on LinkedIn on August 22, 2025.*

Amidst artificial intelligence hype, how many hypers have answered the question, 'what exactly is "intelligence"?' Pop-philosopher and Silicon Valley icon, Nick Bostrom, certainly hasn't, in his decade-old book I review in the article linked below. We keep arguing about AI, AGI and â€œsuperintelligenceâ€ as if â€œintelligenceâ€ were a settled term. It isnâ€™t. Everyoneâ€™s waving at an intuition while measuring something else entirely. (Usually â€œhow well it does this one benchmark after being spoon-fed the internetâ€.) We often conflate: ğŸï¸ğŸ§  Speed with smarts (fast â‰  intelligent; a jet-powered potato is still a potato). ğŸ’¾ğŸ† Memorisation with mastery (regurgitation isnâ€™t reason). ğŸ©ğŸŒ Narrow tricks with generality (party piece â‰  mind). ğŸ“ŠğŸŒ IQ-ish scores with capability in the world (life is not a multiple-choice exam). A workable definition (v1.0) Intelligence is the capacity to achieve a broad range of goals in novel, uncertain environments, using limited data and limited resources, by forming, testing and revising models of the world, individually and with others. Plain English: can it figure things out it hasnâ€™t seen before, under pressure, without wasting time, data or electricity, and can it collaborate? How to tell if something deserves the â€œintelligentâ€ label- Ask whether it shows: ğŸŒ Generality â€“ performs across different kinds of tasks, not just more of the same. ğŸ”„ Transfer & abstraction â€“ reuses what it learnt there to solve problems here. ğŸ’§ Sample efficiency â€“ learns from small hints, not a firehose. ğŸ›¡ï¸ Robustness â€“ copes when the world shifts under its feet (distribution shift, anyone?). â™Ÿï¸ Causality & planning â€“ reasons about why things happen and chooses what to do next. ğŸ› ï¸ Self-correction â€“ notices and fixes its own mistakes without being handheld. ğŸ¤ Social competence â€“ coordinates with humans (and other agents) without becoming a menace. ğŸ”‹ Resource frugality â€“ does the above without burning a small power station. If your system falls over outside its training data, congratulating it for â€œintelligenceâ€ is like calling a sat-nav a cartographer. Why this matters Safety & governance:Â You canâ€™t regulate what you canâ€™t define. Benchmarks arenâ€™t a constitution. R&D focus:Â Rewarding generality and sample efficiency changes what labs build. Human capital:Â Recognising social, causal and adaptive skills stops us treating people like slow servers. A pocket test Before saying â€œintelligentâ€, try:Â â€œWould I trust this to handle a new situation, with tight time/energy/data budgets, in a way that improves after its first try, and play nicely with others while doing it?â€Â If not, perhaps itâ€™s powerful, impressive, usefulâ€¦ just not intelligent. Iâ€™ve offeredÂ Definition v1.0. Tear it apart, improve it, or replace it; but letâ€™s stop arguing about super-X before weâ€™ve agreed what X is. #AI #AGI #Intelligence #MachineLearning #CognitiveScience #Ethics

[View on LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7364578338889228288)
