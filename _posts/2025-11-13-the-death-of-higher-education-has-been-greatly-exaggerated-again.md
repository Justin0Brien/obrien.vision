---
layout: post
title: "The death of higher education has been greatly exaggerated, again."
date: 2025-11-13
categories: [linkedin]
tags: [linkedin, social-media]
author: "Justin O'Brien"
excerpt: "The death of higher education has been greatly exaggerated, again. Ian Richardsonâ€™s recent piece in Times Higher Education argues that higher education has â€œdismally failedâ€ to engage with AI and risks being displaced..."
linkedin_url: "https://www.linkedin.com/feed/update/urn:li:activity:7394675433876824064"
image: "/assets/images/posts/2025-11-13-the-death-of-higher-education-has-been-greatly-exaggerated-again/1762880549257.jpg"
thumbnail: "/assets/images/posts/2025-11-13-the-death-of-higher-education-has-been-greatly-exaggerated-again/1762880549257.jpg"
---

![LinkedIn post image](/assets/images/posts/2025-11-13-the-death-of-higher-education-has-been-greatly-exaggerated-again/1762880549257.jpg)

*Originally posted on LinkedIn on November 13, 2025.*

The death of higher education has been greatly exaggerated, again. Ian Richardsonâ€™s recent piece in Times Higher Education argues that higher education has â€œdismally failedâ€ to engage with AI and risks being displaced by nimbler players. His provocation may be useful but his diagnosis is not. First, the easy bit: yes, a lot of institutional AI activity is performative ğŸ­. A few licences, a detection tool, a hastily written AI policy, an ethics paragraph, and a hope that someone in IT will sort the rest. That is not strategy. That is **wishful procurement** ğŸ’¸. But the bigger claim, that â€œthe sectorâ€ has uniquely failed to engage, is analytically empty ğŸ§©. There is no single sector. A small, underfunded regional university ğŸ« operating under punitive regulation âš–ï¸ and a staffing crisis does not have the same room for manoeuvre as a well-capitalised research giant ğŸ›ï¸. Treating them as one homogenous laggard is a category error, not insight. There is also the awkward fact that many universities are already doing serious work: assessment redesign, internal copilots ğŸ§©, sector principles, home-grown tools ğŸ› ï¸, staff development, data governance frameworks ğŸ”. Imperfect, patchy, slow, yes. But not the cartoon of aristocratic indifference. The comparisons with banking, consulting and healthcare miss the point. Banks can close branches and nudge customers onto apps ğŸ’³. Universities cannot simply â€œclose seminarsâ€ and ship everyone to chatbots without colliding with their public missions, professional standards, labour agreements and (quite reasonably) suspicious students. Slowness is not always complacency. Sometimes it is the cost of remembering that education is not just another tech product ğŸ§­. If there is a real risk of irrelevance, it does not come from failing to â€œembrace AIâ€ with enough enthusiasm. It comes from outsourcing the thinking. If your institutionâ€™s AI response is primarily detection tools and marketing copy then you have a problem. If, instead, it is redesigning assessment so that AI is assumed, not feared; putting data protection, academic freedom and labour conditions at the centre; and investing in evidence, not just hype ğŸ“Š: then you are at least in the right game. AI is not a salvation narrative or a stick to beat academics with. It is an infrastructure question: who sets the rules and how that aligns with what a university is for. By all means read pieces that shout â€œengage or dieâ€ â˜ ï¸. Then ask a duller, better question: â€œShow me, in writing, how our AI choices improve learning ğŸ“š, protect people ğŸ§â€â™€ï¸, and strengthen our public role ğŸŒ. If you cannot, then the risk is not that we are too slow on AI. The risk is that we are no longer doing our job.â€ ğŸ”— Times Higher Link: https://lnkd.in/df8shFWY #HigherEducation #AIinEducation #DigitalStrategy #UniversityLeadership #Ethics #AcademicFreedom #AIIntegration

[View on LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7394675433876824064)
