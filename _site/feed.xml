<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4001/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4001/" rel="alternate" type="text/html" /><updated>2025-08-04T17:51:42+01:00</updated><id>http://localhost:4001/feed.xml</id><title type="html">Justin O’Brien</title><subtitle>Data Visualization • Analysis • Insights.  Exploring employment dynamics, career transitions, and economic trends through interactive visualizations and evidence-based research.</subtitle><entry><title type="html">Visualizing Career Transitions: The Story Behind the Sankey Diagram</title><link href="http://localhost:4001/2025/08/01/visualizing-career-transitions/" rel="alternate" type="text/html" title="Visualizing Career Transitions: The Story Behind the Sankey Diagram" /><published>2025-08-01T11:00:00+01:00</published><updated>2025-08-01T11:00:00+01:00</updated><id>http://localhost:4001/2025/08/01/visualizing-career-transitions</id><content type="html" xml:base="http://localhost:4001/2025/08/01/visualizing-career-transitions/"><![CDATA[<h1 id="visualizing-career-transitions-the-story-behind-the-sankey-diagram">Visualizing Career Transitions: The Story Behind the Sankey Diagram</h1>

<p>When I set out to visualize employment outcomes for professionals aged 50+ following redundancy, I knew the story was complex. Unlike a simple before-and-after comparison, career transitions unfold over time, with multiple pathways and outcomes that shift as months pass.</p>

<p>The <a href="/sankey.html">interactive Sankey diagram</a> I created tells this story through the flow of percentages across different time periods, revealing patterns that might be lost in traditional charts or tables.</p>

<h2 id="why-a-sankey-diagram">Why a Sankey Diagram?</h2>

<p>Sankey diagrams excel at showing flow and transition. They’re perfect for visualizing:</p>

<ul>
  <li><strong>Proportional relationships</strong>: The width of each flow represents the percentage of people following that path</li>
  <li><strong>Multiple outcomes</strong>: Unlike pie charts that show a single moment, Sankey diagrams can show how outcomes evolve</li>
  <li><strong>Complex pathways</strong>: Some people find professional jobs quickly, others cycle through different states before settling into long-term outcomes</li>
</ul>

<h2 id="the-data-story">The Data Story</h2>

<p>The visualization reveals several key insights:</p>

<h3 id="early-struggles">Early Struggles</h3>

<p>At 3 months post-redundancy, 65% of professionals aged 50+ remain unemployed. This stark figure highlights the immediate challenge this demographic faces in the job market.</p>

<h3 id="gradual-recovery">Gradual Recovery</h3>

<p>By 6 months, the unemployment rate drops to 38%, and by 12 months to 30%. However, this recovery isn’t just about finding similar professional roles – it’s about adaptation and compromise.</p>

<h3 id="the-new-normal">The New Normal</h3>

<p>After 24 months, the data shows a “new normal” where:</p>

<ul>
  <li>45% eventually return to professional roles</li>
  <li>10% accept lower-paid positions</li>
  <li>15% become self-employed</li>
  <li>30% remain unemployed long-term</li>
</ul>

<h2 id="design-decisions">Design Decisions</h2>

<p>Several design choices enhance the storytelling:</p>

<h3 id="color-coding">Color Coding</h3>

<ul>
  <li><strong>Blue</strong>: Professional employment (positive outcome)</li>
  <li><strong>Orange</strong>: Lower-paid employment (compromise outcome)</li>
  <li><strong>Green</strong>: Self-employment (alternative pathway)</li>
  <li><strong>Red</strong>: Unemployment (challenge outcome)</li>
</ul>

<h3 id="gradients">Gradients</h3>

<p>Links between nodes use gradients that blend the source and target colors, visually representing the transition between different employment states.</p>

<h3 id="time-labels">Time Labels</h3>

<p>Clear time markers help users understand the progression and see how outcomes evolve over the critical first two years.</p>

<h3 id="responsive-design">Responsive Design</h3>

<p>The diagram adapts to different screen sizes while maintaining readability and impact.</p>

<h2 id="technical-implementation">Technical Implementation</h2>

<p>Built with D3.js and the d3-sankey plugin, the visualization processes flow data to create smooth, proportional connections between employment states across time periods.</p>

<p>Key technical features:</p>

<ul>
  <li>Responsive SVG rendering</li>
  <li>Interactive tooltips showing exact percentages</li>
  <li>Hover effects to highlight specific flows</li>
  <li>Gradient definitions for smooth color transitions</li>
</ul>

<h2 id="the-broader-context">The Broader Context</h2>

<p>This visualization is part of a larger investigation into age-related employment challenges. The data combines insights from multiple sources including ONS statistics, Labour Force Survey data, and research from organizations like Ageing Better and the Resolution Foundation.</p>

<p>The goal isn’t just to present statistics, but to make the human impact of redundancy visible and understandable to policymakers, employers, and the affected individuals themselves.</p>

<h2 id="whats-next">What’s Next?</h2>

<p>This Sankey diagram opens up several avenues for further exploration:</p>

<ul>
  <li>Regional variations in outcomes</li>
  <li>Industry-specific transition patterns</li>
  <li>The role of skills in successful transitions</li>
  <li>Interventions that improve outcomes</li>
</ul>

<p>I’m continuing to develop interactive tools that make employment data more accessible and actionable. Each visualization aims to bridge the gap between raw statistics and human understanding.</p>

<hr />

<p><em>Interested in commissioning similar visualizations or discussing employment data analysis? <a href="/contact/">Get in touch</a> to explore collaboration opportunities.</em></p>]]></content><author><name>Justin O'Brien</name></author><category term="data-visualization" /><category term="employment" /><category term="sankey-diagram" /><category term="d3js" /><category term="career-transitions" /><category term="unemployment" /><summary type="html"><![CDATA[Exploring the design decisions and data insights behind the interactive Sankey diagram showing employment outcomes for professionals aged 50+ after redundancy.]]></summary></entry><entry><title type="html">Fixing Universities</title><link href="http://localhost:4001/2025/08/01/fixing-universities/" rel="alternate" type="text/html" title="Fixing Universities" /><published>2025-08-01T00:00:00+01:00</published><updated>2025-08-01T00:00:00+01:00</updated><id>http://localhost:4001/2025/08/01/fixing-universities</id><content type="html" xml:base="http://localhost:4001/2025/08/01/fixing-universities/"><![CDATA[]]></content><author><name>Justin O'Brien</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Beating The Odds: Four Months in Mid-Life Employment Limbo</title><link href="http://localhost:4001/2025/07/31/beating-the-odds/" rel="alternate" type="text/html" title="Beating The Odds: Four Months in Mid-Life Employment Limbo" /><published>2025-07-31T00:00:00+01:00</published><updated>2025-07-31T00:00:00+01:00</updated><id>http://localhost:4001/2025/07/31/beating-the-odds</id><content type="html" xml:base="http://localhost:4001/2025/07/31/beating-the-odds/"><![CDATA[<p><img src="/assets/images/posts/2025-07-31-beating-the-odds/career-odds.jpg" alt="Professional looking person with graphs and career pathway charts in background" /></p>

<h2 id="four-months-in-mid-life-employment-limbo">Four Months in Mid-Life Employment Limbo</h2>

<p>I was made redundant 4 months ago today.</p>

<p><strong>31 March:</strong> I executed the traditional farewell ritual of the mid-career professional: an almost-imperceptible shrug in the general direction of the photocopier and a short walk to the car park. No speeches, no novelty cake, not even a limp balloon. Just me, a cardboard box and the sort of existential soundtrack you normally get in French cinema.</p>

<p><strong>1 April:</strong> New month, new life. I was up with the larks, pounding the cross-trainer in a heroic attempt to sculpt a “new me”. Resistance machines were conquered, endorphins flowed, and—for a glorious forty-eight hours—I was basically the poster child for Mid-Life Reinvention.</p>

<p><strong>3 April:</strong> Doughnuts happened. Then ice cream. If Ben &amp; Jerry ever need to boost quarterly sales, they should simply make more fifty-somethings redundant; we’ll do the heavy lifting.</p>

<p>Fast-forward four months: zero salary, zero job, and—rather paradoxically—a very busy diary. I’ve uploaded a few LinkedIn posts and articles, but that’s the tip of the iceberg. It turns out that finding work in 2025 is very different from the last time I was in the job market. That was when Mark Zuckerberg was still in high school, Elon Musk had yet to be fired from PayPal, and Google was a long way from becoming a verb.</p>

<p>So what’s it actually like, drifting through middle-age employment limbo with a gym membership you no longer use and a freezer full of salted-caramel regret?</p>

<p><strong>It’s actually not too bad, apart from the whole zero salary thing.</strong></p>

<h2 id="the-numbers-game">The Numbers Game</h2>

<p>And I’m not alone. Exiting a professional job in your fifties (unwillingly) is not a rare occurrence, especially in 2025.</p>

<p>To figure out what happens next, I turned not to necromancy or tarot cards but to statistics and data visualisation. I’ve done a little research, the sources for which you’ll find at the end of this article. There isn’t a single definitive source of data so I’ve extracted some figures and done some careful extrapolation. And guesswork.</p>

<iframe src="/sankey.html" width="100%" height="600" frameborder="0" style="border: 1px solid #ddd; border-radius: 8px; margin: 20px 0;"></iframe>

<h3 id="figure-1-career-pathways-after-redundancy-at-50">Figure 1. Career Pathways After Redundancy at 50+</h3>

<p>Should I be worried that after 4 months I don’t have a job - any job? Not really. Only <strong>14% of my age group have another professional job within 3 months</strong> of leaving the old one. Another 14% are in lower paid work, and 7% say they’re “self-employed”, but <strong>two thirds are still jobless</strong>.</p>

<p>This jobless figure does drop and two years after redundancy only 20% are unemployed, although long term this goes up to nearly a third.</p>

<p>Should I be concerned that the odds are against me: I have a <strong>less than evens chance</strong> of landing in a professional job sometime in the next few years?</p>

<h2 id="understanding-the-odds">Understanding the Odds</h2>

<p>Some people resist any discussion of probability, preferring an unexamined optimism that screens out unfavourable statistics. I take the opposite view: the more granular the data—baseline rates, confidence intervals, omitted caveats—the better. Equipped with that information, we can assess alternatives rationally rather than intuitively.</p>

<p>For me, this is what it means to <strong>beat the odds</strong>. It is not a matter of willing a coin to land heads or expecting double-sixes on demand; it is a systematic appraisal of the distribution of outcomes under different courses of action and an informed adjustment of strategy in light of those probabilities.</p>

<p><strong>Chance remains a constant, but its impact can be moderated when we understand, rather than ignore, the numbers.</strong></p>

<p>There’s much more to say about what these figures tell us, but even I know that an article full of numbers should be brief.</p>

<h2 id="your-turn">Your Turn</h2>

<p>How did your own post-redundancy odds play out? Drop a note below—stats or stories equally welcome.</p>

<hr />

<h2 id="sources">Sources</h2>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Centre for Ageing Better, Work</td>
          <td>State of Ageing in 2020 – <a href="https://ageing-better.org.uk/work-state-ageing-2020">ageing-better.org.uk/work-state-ageing-2020</a></td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p>Resolution Foundation, A U-shaped crisis: the impact of the COVID-19 crisis on older workers – <a href="https://www.resolutionfoundation.org/publications/a-u-shaped-crisis/">resolutionfoundation.org/publications/a-u-shaped-crisis</a></p>
  </li>
  <li>
    <p>Resolution Foundation, “COVID-19 crisis has caused the biggest annual employment fall for older workers since the 1980s” – <a href="https://www.resolutionfoundation.org/press-releases/covid-19-crisis-has-caused-the-biggest-annual-employment-fall-for-older-workers-since-the-1980s/">resolutionfoundation.org/press-releases</a></p>
  </li>
  <li>
    <p>The Guardian, “Over-50s who lose jobs much more likely to stay unemployed, study finds” – <a href="https://www.theguardian.com/society/2021/jan/18/over-50s-who-lose-jobs-much-more-likely-to-stay-unemployed-study-finds">theguardian.com/society/2021/jan/18</a></p>
  </li>
  <li>
    <p>Rest Less, “Redundancies Amongst the Over 50s Have Nearly Tripled in a Year” – <a href="https://wiseage.org.uk/2021/04/redundancies-amongst-the-over-50s-have-nearly-tripled-in-a-year/">wiseage.org.uk/2021/04</a></p>
  </li>
  <li>
    <p>Centre for Ageing Better, Redundancy support for Over 50s – <a href="https://ageing-better.org.uk/redundancy-support-over-50s">ageing-better.org.uk/redundancy-support-over-50s</a></p>
  </li>
  <li>
    <p>Office for National Statistics, Analysis of Job Changers and Stayers – <a href="https://www.ons.gov.uk/economy/nationalaccounts/uksectoraccounts/compendium/economicreview/april2019/analysisofjobchangersandstayers">ons.gov.uk/economy/nationalaccounts</a></p>
  </li>
  <li>
    <p>Centre for Ageing Better, The State of Ageing 2022 – <a href="https://ageing-better.org.uk/state-of-ageing">ageing-better.org.uk/state-of-ageing</a></p>
  </li>
  <li>
    <p>Office for National Statistics, Dataset RED02: Redundancies by age, industry and region – <a href="https://www.ons.gov.uk/employmentandlabourmarket/peoplenotinwork/redundancies/datasets/redundanciesbyindustryagesexandreemploymentratesred02">ons.gov.uk/employmentandlabourmarket</a></p>
  </li>
  <li>Office for National Statistics, Employment in the UK: July 2025 bulletin – <a href="https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/employmentandemployeetypes/bulletins/employmentintheuk/july2025">ons.gov.uk/employmentandlabourmarket</a></li>
</ul>]]></content><author><name>Justin O'Brien</name></author><category term="employment" /><category term="career" /><category term="redundancy" /><category term="job-search" /><category term="over-50s" /><category term="unemployment" /><category term="career-transition" /><category term="employment-statistics" /><category term="professional-development" /><summary type="html"><![CDATA[I was made redundant 4 months ago today. Fast-forward four months: zero salary, zero job, and—rather paradoxically—a very busy diary. So what's it actually like, drifting through middle-age employment limbo with a gym membership you no longer use and a freezer full of salted-caramel regret?]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4001/assets/images/posts/2025-07-31-beating-the-odds/career-odds.jpg" /><media:content medium="image" url="http://localhost:4001/assets/images/posts/2025-07-31-beating-the-odds/career-odds.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How To Murder A University</title><link href="http://localhost:4001/2025/07/30/how-to-murder-a-university/" rel="alternate" type="text/html" title="How To Murder A University" /><published>2025-07-30T00:00:00+01:00</published><updated>2025-07-30T00:00:00+01:00</updated><id>http://localhost:4001/2025/07/30/how-to-murder-a-university</id><content type="html" xml:base="http://localhost:4001/2025/07/30/how-to-murder-a-university/"><![CDATA[]]></content><author><name>Justin O'Brien</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Beyond The Balance Sheet</title><link href="http://localhost:4001/2025/07/28/beyond-the-balance-sheet/" rel="alternate" type="text/html" title="Beyond The Balance Sheet" /><published>2025-07-28T00:00:00+01:00</published><updated>2025-07-28T00:00:00+01:00</updated><id>http://localhost:4001/2025/07/28/beyond-the-balance-sheet</id><content type="html" xml:base="http://localhost:4001/2025/07/28/beyond-the-balance-sheet/"><![CDATA[]]></content><author><name>Justin O'Brien</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Governmental Shrugs</title><link href="http://localhost:4001/2025/07/25/governmental-shrugs/" rel="alternate" type="text/html" title="Governmental Shrugs" /><published>2025-07-25T00:00:00+01:00</published><updated>2025-07-25T00:00:00+01:00</updated><id>http://localhost:4001/2025/07/25/governmental-shrugs</id><content type="html" xml:base="http://localhost:4001/2025/07/25/governmental-shrugs/"><![CDATA[]]></content><author><name>Justin O'Brien</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Ethics in Artificial Intelligence: Yes, There Is a Problem</title><link href="http://localhost:4001/2025/07/23/ethics-in-artificial-intelligence/" rel="alternate" type="text/html" title="Ethics in Artificial Intelligence: Yes, There Is a Problem" /><published>2025-07-23T00:00:00+01:00</published><updated>2025-07-23T00:00:00+01:00</updated><id>http://localhost:4001/2025/07/23/ethics-in-artificial-intelligence</id><content type="html" xml:base="http://localhost:4001/2025/07/23/ethics-in-artificial-intelligence/"><![CDATA[<p><img src="/assets/images/posts/2025-07-23-ethics-in-artificial-intelligence/ai-ethics.jpg" alt="Abstract visualization of AI neural networks with ethical scales and human silhouettes" /></p>

<h2 id="a-clear-and-candid-guide-to-ai-ethics">A Clear and Candid Guide to AI Ethics</h2>

<p>Artificial intelligence (AI) has catapulted from the plaything of graduate students to the digital weather system that now soaks every corner of the economy. The upsides are dazzling; the downsides, well, they’re the reason you’re reading this article instead of a holiday brochure.</p>

<p>This paper peers—torch in hand—into the trickier nooks of AI from a global vantage point. We’ll rummage through its resource guzzling, copyright snacking, bias-soaked data diet, the Silicon Valley swagger that births it, and the many honourable (and not-so-honourable) uses already on parade.</p>

<h2 id="energy-and-human-resource-consumption">Energy and Human Resource Consumption</h2>

<h3 id="the-environmental-footprint-of-ai">The Environmental Footprint of AI</h3>

<p>Training large AI models requires enormous computational power, translating into heavy energy usage and a substantial carbon footprint. For example, the training of OpenAI’s GPT-3 model is estimated to have consumed <strong>1,287 MWh of electricity</strong>, emitting over <strong>550 metric tons of CO₂</strong> – on par with hundreds of transatlantic flights<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>. This process also used more than 700,000 liters of water for cooling data centre servers<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>.</p>

<p>Globally, data centres (which host AI workloads among other tasks) account for about <strong>1.5% of electricity consumption</strong> (around 415 TWh in 2024), a share expected to roughly double by 2030 due to AI growth<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup><sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup>. In practical terms, that means data centres could soon draw nearly 945 TWh annually – about as much power as the entire country of Japan uses in a year<sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">5</a></sup>.</p>

<p>Major tech hubs like the US, Europe and China currently consume 85% of data centre energy<sup id="fnref:6"><a href="#fn:6" class="footnote" rel="footnote" role="doc-noteref">6</a></sup><sup id="fnref:7"><a href="#fn:7" class="footnote" rel="footnote" role="doc-noteref">7</a></sup>, highlighting a global disparity. Even after models are trained, the energy for running AI (“inference”) at scale can eclipse training costs – one study noted that inference could comprise 90% of an AI model’s total energy lifecycle as millions of users prompt these models daily<sup id="fnref:8"><a href="#fn:8" class="footnote" rel="footnote" role="doc-noteref">8</a></sup>.</p>

<h3 id="the-human-labour-behind-automated-ai">The Human Labour Behind “Automated” AI</h3>

<p>Less visible but equally critical is the human labour powering AI development. Behind every “smart” AI system are often thousands of human workers who label data, moderate content, and train AI models – tasks that can be repetitive, grueling, or psychologically taxing.</p>

<p>In 2021, OpenAI quietly outsourced the job of filtering toxic and harmful content (to make ChatGPT safer) to contractors in Kenya, <strong>paying them less than $2 per hour</strong>. These workers had to read and label tens of thousands of disturbing text snippets – including descriptions of child sexual abuse, torture, and violence – so that the AI could learn to recognise and avoid producing such content<sup id="fnref:9"><a href="#fn:9" class="footnote" rel="footnote" role="doc-noteref">9</a></sup>.</p>

<p>The psychological toll was enormous: moderators reported trauma, anxiety and lasting mental health damage from constant exposure to graphic material<sup id="fnref:10"><a href="#fn:10" class="footnote" rel="footnote" role="doc-noteref">10</a></sup><sup id="fnref:11"><a href="#fn:11" class="footnote" rel="footnote" role="doc-noteref">11</a></sup>. Several have since filed petitions and lawsuits (for instance, in Kenya) over exploitative conditions – citing low pay (around $1.50–$3 an hour), inadequate counseling support, and even abrupt dismissals after the projects ended<sup id="fnref:12"><a href="#fn:12" class="footnote" rel="footnote" role="doc-noteref">12</a></sup><sup id="fnref:13"><a href="#fn:13" class="footnote" rel="footnote" role="doc-noteref">13</a></sup>.</p>

<p>This “ghost work” underpins not just ChatGPT but many AI services – from social media moderation to self-driving car vision – often outsourced to developing countries where labour is cheap.</p>

<h2 id="copyright-and-creator-rights">Copyright and Creator Rights</h2>

<p>AI’s voracious appetite for data has it nibbling at every creative buffet—books, art, code, music—often without so much as a “may I?”. Contemporary AI models learn from vast datasets scraped from the internet – encompassing books, articles, code, images, music and more – much of which is copyrighted material obtained without explicit consent from the authors or artists.</p>

<h3 id="unconsented-training-data">Unconsented Training Data</h3>

<p>Writers, visual artists, musicians and other creators have grown alarmed at AI models being trained on their work. In mid-2023, a group of prominent authors – including <strong>Michael Chabon, Jodi Picoult and George R.R. Martin</strong> – sued OpenAI, alleging that their novels and essays were used to train ChatGPT without consent<sup id="fnref:14"><a href="#fn:14" class="footnote" rel="footnote" role="doc-noteref">14</a></sup><sup id="fnref:15"><a href="#fn:15" class="footnote" rel="footnote" role="doc-noteref">15</a></sup>.</p>

<p>They pointed out that the chatbot could accurately summarise their books or imitate their writing styles, implying it had effectively ingested and learned from their copyrighted texts<sup id="fnref:16"><a href="#fn:16" class="footnote" rel="footnote" role="doc-noteref">16</a></sup>. This lawsuit is one of several class actions by authors and publishers against AI firms, and it followed similar cases by visual artists against generative AI image companies<sup id="fnref:17"><a href="#fn:17" class="footnote" rel="footnote" role="doc-noteref">17</a></sup><sup id="fnref:18"><a href="#fn:18" class="footnote" rel="footnote" role="doc-noteref">18</a></sup>.</p>

<p>In a landmark example, a class-action suit <strong>Andersen v. Stability AI</strong> was filed in 2023 by a group of artists after they discovered the AI image generator Stable Diffusion had been trained on 5 billion images scraped from the web (LAION dataset), including their own artworks, without any permission<sup id="fnref:19"><a href="#fn:19" class="footnote" rel="footnote" role="doc-noteref">19</a></sup><sup id="fnref:20"><a href="#fn:20" class="footnote" rel="footnote" role="doc-noteref">20</a></sup>.</p>

<h3 id="legal-and-ethical-tensions">Legal and Ethical Tensions</h3>

<p>Legally, the question of whether using copyrighted data for AI training is “fair use” or infringement is still being decided. In a February 2025 decision, a U.S. court (<strong>Thomson Reuters v. ROSS</strong>) held that wholesale copying of a competitor’s copyrighted material (legal case summaries from Westlaw) to train an AI research tool was not fair use<sup id="fnref:21"><a href="#fn:21" class="footnote" rel="footnote" role="doc-noteref">21</a></sup><sup id="fnref:22"><a href="#fn:22" class="footnote" rel="footnote" role="doc-noteref">22</a></sup>.</p>

<p>The judge noted that the AI in that case wasn’t even a generative model, but a search tool that repackaged the original texts, directly harming the copyright owner’s market<sup id="fnref:23"><a href="#fn:23" class="footnote" rel="footnote" role="doc-noteref">23</a></sup><sup id="fnref:24"><a href="#fn:24" class="footnote" rel="footnote" role="doc-noteref">24</a></sup>. While generative AI may muddy the waters (since outputs aren’t verbatim copies, but can be derivative in style or content), the legal trend suggests courts are wary of unfettered, unlicensed use of copyrighted datasets.</p>

<h3 id="toward-solutions--consent-and-transparency">Toward Solutions – Consent and Transparency</h3>

<p>Policymakers are starting to respond. The draft <strong>EU AI Act</strong> includes provisions that AI developers must disclose any copyrighted material used in training their models<sup id="fnref:25"><a href="#fn:25" class="footnote" rel="footnote" role="doc-noteref">25</a></sup><sup id="fnref:26"><a href="#fn:26" class="footnote" rel="footnote" role="doc-noteref">26</a></sup>. European lawmakers explicitly added a requirement that generative AI systems like ChatGPT publish summaries of the copyrighted data they were trained on, aiming to introduce transparency and enable rightsholders to claim misuse<sup id="fnref:27"><a href="#fn:27" class="footnote" rel="footnote" role="doc-noteref">27</a></sup>.</p>

<h2 id="training-data-and-bias">Training Data and Bias</h2>

<p>The ancient maxim “garbage in, garbage out” gets a silicon makeover here. Feed an AI dodgy data and you’ll get dodgy decisions—only faster and at scale.</p>

<h3 id="opaque-datasets-and-hidden-biases">Opaque Datasets and Hidden Biases</h3>

<p>Many advanced AI models are trained on colossal datasets that are not fully disclosed to the public or regulators. For instance, when OpenAI released GPT-4 in 2023, it notably provided <strong>no details</strong> about the model’s architecture, training methods, or dataset composition, citing competition and safety concerns<sup id="fnref:28"><a href="#fn:28" class="footnote" rel="footnote" role="doc-noteref">28</a></sup><sup id="fnref:29"><a href="#fn:29" class="footnote" rel="footnote" role="doc-noteref">29</a></sup>.</p>

<p>While trade secrecy is understandable, this opacity has a direct ethical impact: without knowing what data an AI was trained on, it’s “impossible to evaluate” what biases or blind spots might be built into it<sup id="fnref:30"><a href="#fn:30" class="footnote" rel="footnote" role="doc-noteref">30</a></sup>.</p>

<h3 id="bias-in-bias-out--examples">Bias in, Bias Out – Examples</h3>

<p>When biased data goes in, discriminatory outcomes come out. A notorious example was <strong>Amazon’s AI recruiting tool</strong>, an algorithm developed to screen resumes. It was trained on ten years of past hiring data – which were skewed toward male candidates (reflecting the tech industry’s male dominance)<sup id="fnref:31"><a href="#fn:31" class="footnote" rel="footnote" role="doc-noteref">31</a></sup><sup id="fnref:32"><a href="#fn:32" class="footnote" rel="footnote" role="doc-noteref">32</a></sup>.</p>

<p>The AI “taught itself” that male applicants were preferable and began penalising resumes that mentioned “women’s” (as in “women’s chess club”), and downgrading graduates of women’s colleges<sup id="fnref:33"><a href="#fn:33" class="footnote" rel="footnote" role="doc-noteref">33</a></sup><sup id="fnref:34"><a href="#fn:34" class="footnote" rel="footnote" role="doc-noteref">34</a></sup>. In effect, the system became sexist, systematically filtering out qualified women. Amazon’s engineers tried to correct the specific flags, but they couldn’t guarantee the AI wouldn’t find new ways to discriminate, so the project was eventually scrapped<sup id="fnref:35"><a href="#fn:35" class="footnote" rel="footnote" role="doc-noteref">35</a></sup><sup id="fnref:36"><a href="#fn:36" class="footnote" rel="footnote" role="doc-noteref">36</a></sup>.</p>

<p>Another well-documented case is in criminal justice: risk assessment algorithms used by courts to predict reoffending have exhibited racial bias. ProPublica’s famous 2016 investigation into the <strong>COMPAS system</strong> found that black defendants were falsely labeled “high risk” at nearly twice the rate of white defendants, while white defendants were more frequently mislabeled as low risk<sup id="fnref:37"><a href="#fn:37" class="footnote" rel="footnote" role="doc-noteref">37</a></sup>.</p>

<h2 id="the-silicon-valley-ethos-and-the-drive-to-innovate">The Silicon Valley Ethos and the Drive to Innovate</h2>

<p>Silicon Valley’s original mantra—”move fast and break things”—is all fun and games until the “things” include society.</p>

<h3 id="from-motto-to-liability">From Motto to Liability</h3>

<p>In the startup heyday, “move fast and break things” was celebrated as a recipe for disrupting incumbents and achieving technological leaps. However, when it comes to AI systems that can affect millions of lives, this approach can be dangerously reckless. A recent poll found that <strong>72% of Americans prefer AI development to slow down</strong> with more guardrails, versus only 8% who want it to speed up<sup id="fnref:38"><a href="#fn:38" class="footnote" rel="footnote" role="doc-noteref">38</a></sup><sup id="fnref:39"><a href="#fn:39" class="footnote" rel="footnote" role="doc-noteref">39</a></sup>.</p>

<p>High-profile mishaps have validated these fears: from chatbots that went awry spouting misinformation or hate, to social networks unleashing algorithms that amplified societal divisions. The “launch now, fix later” mentality is being increasingly questioned.</p>

<h3 id="profit-driven-innovation-and-moral-hazard">Profit-Driven Innovation and Moral Hazard</h3>

<p>Silicon Valley’s ecosystem runs on venture capital and the promise of massive profits. This can incentivise a single-minded focus on growth metrics and market capture, potentially overshadowing ethical considerations. AI has become a competitive arms race among tech giants and startups, with enormous financial stakes – which can lead to corners being cut.</p>

<p>Gary Marcus observed a “moral descent” in Big Tech: as companies grew more powerful and profitable, “the desire to do good decreases… in the quest for growth”<sup id="fnref:40"><a href="#fn:40" class="footnote" rel="footnote" role="doc-noteref">40</a></sup>. He argues that many firms talk about altruistic missions, but in recent years have prioritised profit maximisation at the expense of users and society<sup id="fnref:41"><a href="#fn:41" class="footnote" rel="footnote" role="doc-noteref">41</a></sup>.</p>

<h2 id="uses-and-misuses-of-ai">Uses and Misuses of AI</h2>

<p>AI is a dual-use tool: the same algorithms that power beneficial applications can be misappropriated for malicious or harmful ends.</p>

<h3 id="ai-in-social-media-deepfakes-and-algorithmic-amplification">AI in Social Media: Deepfakes and Algorithmic Amplification</h3>

<h4 id="deepfakes-and-misinformation">Deepfakes and Misinformation</h4>

<p>Deepfakes are hyper-realistic fake videos or audio generated by AI, often depicting someone saying or doing things they never did. In the wrong hands, deepfakes can be a potent weapon for misinformation, political propaganda, or personal harassment.</p>

<p>A striking statistic: an analysis in 2023 found that <strong>98% of deepfake videos online were pornographic</strong>, targeting women in 99% of cases<sup id="fnref:42"><a href="#fn:42" class="footnote" rel="footnote" role="doc-noteref">42</a></sup>. In other words, the vast majority of deepfakes globally consist of non-consensual sexual images – typically a woman’s face superimposed on explicit content – effectively a high-tech form of revenge porn or voyeurism.</p>

<h4 id="algorithmic-amplification-of-harmful-content">Algorithmic Amplification of Harmful Content</h4>

<p>Social media algorithms – the content recommendation AIs on Facebook, YouTube, TikTok, etc. – determine what billions of people see in their feeds. Their optimisation for engagement can lead to the amplification of extreme or harmful content, creating echo chambers and fueling polarisation.</p>

<p>Facebook’s own algorithm changes were found to preferentially boost content that sparked anger or intense reactions, which tended to be divisive posts or misinformation, thus contributing to a more toxic discourse<sup id="fnref:43"><a href="#fn:43" class="footnote" rel="footnote" role="doc-noteref">43</a></sup><sup id="fnref:44"><a href="#fn:44" class="footnote" rel="footnote" role="doc-noteref">44</a></sup>.</p>

<h3 id="fraud-and-scams-voice-cloning-and-phishing-automation">Fraud and Scams: Voice Cloning and Phishing Automation</h3>

<h4 id="voice-cloning-and-imposter-scams">Voice Cloning and “Imposter” Scams</h4>

<p>Scammers have begun exploiting trust by using AI to clone voices from just a short recording. In one chilling case, an Arizona mother received a call that mimicked her 15-year-old daughter’s voice perfectly, sobbing that she’d been kidnapped and begging for help<sup id="fnref:45"><a href="#fn:45" class="footnote" rel="footnote" role="doc-noteref">45</a></sup><sup id="fnref:46"><a href="#fn:46" class="footnote" rel="footnote" role="doc-noteref">46</a></sup>. The voice and cries were so convincing that the mother was certain it was her child – the scammers demanded a ransom, threatening violence. It turned out the daughter was safe; the entire call was a hoax using an AI-generated voice.</p>

<p>A survey by security firm McAfee found <strong>70% of people said they might not distinguish a cloned voice from the real thing</strong>, and alarmingly, today’s AI needs only about <strong>3 seconds of audio sample</strong> to reproduce a person’s voice with high fidelity<sup id="fnref:47"><a href="#fn:47" class="footnote" rel="footnote" role="doc-noteref">47</a></sup>.</p>

<h4 id="ai-generated-phishing-and-fraudulent-content">AI-Generated Phishing and Fraudulent Content</h4>

<p>Phishing emails – those fraudulent messages that try to trick you into giving passwords or money – have been around for decades, but AI is supercharging their quality and quantity. With AI language models, a scammer can now generate tailored, grammatically perfect, and context-specific messages by the hundreds.</p>

<p>Europol (the EU’s police agency) warned in 2023 that ChatGPT’s ability to produce highly realistic text with ease makes it a powerful tool for criminals<sup id="fnref:48"><a href="#fn:48" class="footnote" rel="footnote" role="doc-noteref">48</a></sup>.</p>

<h2 id="surveillance-and-policing">Surveillance and Policing</h2>

<p>AI technologies are increasingly employed in surveillance and law enforcement, raising profound ethical issues around privacy, civil liberties, accuracy, and potential abuse of power.</p>

<h3 id="mass-surveillance-and-privacy-erosion">Mass Surveillance and Privacy Erosion</h3>

<p>In authoritarian contexts especially, AI-powered surveillance has been used to oppress and control populations. The starkest example is <strong>Xinjiang, China</strong>, where an estimated million-plus Uyghur Muslims have been subjected to high-tech repression. The Chinese government has deployed a “high-tech network of surveillance” in the region, including ubiquitous cameras with facial recognition, mandatory biometric data collection (DNA, iris scans), and phone/computer data monitoring – all fed into AI systems that flag “suspicious” behaviour<sup id="fnref:49"><a href="#fn:49" class="footnote" rel="footnote" role="doc-noteref">49</a></sup>.</p>

<p>Even outside such extreme cases, the spread of facial recognition in public spaces is blurring the line between security and privacy. There have been at least three known wrongful arrests of Black individuals in the US due to faulty face recognition matches<sup id="fnref:50"><a href="#fn:50" class="footnote" rel="footnote" role="doc-noteref">50</a></sup><sup id="fnref:51"><a href="#fn:51" class="footnote" rel="footnote" role="doc-noteref">51</a></sup>. One case was <strong>Robert Williams in Detroit</strong>: facial recognition misidentified him as a suspect, leading to his arrest and jailing for a crime he didn’t commit. Detroit later settled his lawsuit with a $300k payment and agreed to change its policies<sup id="fnref:52"><a href="#fn:52" class="footnote" rel="footnote" role="doc-noteref">52</a></sup><sup id="fnref:53"><a href="#fn:53" class="footnote" rel="footnote" role="doc-noteref">53</a></sup>.</p>

<h3 id="predictive-policing-and-bias">Predictive Policing and Bias</h3>

<p>Another use of AI in law enforcement is predictive analytics – algorithms that analyse crime data to predict where crimes might occur or who might be involved. While it might sound objective, these systems can perpetuate existing biases in policing data. “Bias in, bias out” applies strongly here.</p>

<p>Simply put, if your AI might ruin someone’s life, double-check it.</p>

<h2 id="employment-hiring-and-workplace-monitoring">Employment, Hiring, and Workplace Monitoring</h2>

<h3 id="ai-in-hiring--fairness-and-transparency">AI in Hiring – Fairness and Transparency</h3>

<p>Companies are increasingly using AI tools to screen job applicants, parse resumes, or even conduct video interviews with algorithmic analysis of facial expressions and tone. The promise is efficiency and objectivity; the peril is encoding bias and opacity in how employment decisions are made.</p>

<p>This lack of transparency and potential for discrimination has prompted regulatory attention. The <strong>EU AI Act</strong> will treat AI in employment as “high-risk,” requiring that such systems be proven non-discriminatory, transparent, and subject to human oversight<sup id="fnref:54"><a href="#fn:54" class="footnote" rel="footnote" role="doc-noteref">54</a></sup><sup id="fnref:55"><a href="#fn:55" class="footnote" rel="footnote" role="doc-noteref">55</a></sup>.</p>

<h3 id="workplace-monitoring-and-algorithmic-management">Workplace Monitoring and “Algorithmic Management”</h3>

<p>Employers have always monitored performance, but AI takes it to new levels of intrusiveness and automation. <strong>Amazon</strong> is the poster child of this trend: in its warehouses, an AI-driven system tracks each worker’s productivity in real time – items scanned, packing speed, “time off task” down to the minute<sup id="fnref:56"><a href="#fn:56" class="footnote" rel="footnote" role="doc-noteref">56</a></sup><sup id="fnref:57"><a href="#fn:57" class="footnote" rel="footnote" role="doc-noteref">57</a></sup>.</p>

<p>If a worker’s metrics fall below a target, the system will automatically generate warnings and even termination notices without a manager’s input<sup id="fnref:58"><a href="#fn:58" class="footnote" rel="footnote" role="doc-noteref">58</a></sup><sup id="fnref:59"><a href="#fn:59" class="footnote" rel="footnote" role="doc-noteref">59</a></sup>. Documents revealed that over a little more than a year, a single Amazon warehouse fired about <strong>300 employees (10% of staff)</strong> purely for productivity shortfalls as decided by this automated system<sup id="fnref:60"><a href="#fn:60" class="footnote" rel="footnote" role="doc-noteref">60</a></sup><sup id="fnref:61"><a href="#fn:61" class="footnote" rel="footnote" role="doc-noteref">61</a></sup>.</p>

<h2 id="military-and-geopolitical-applications">Military and Geopolitical Applications</h2>

<p>Perhaps the most grave domain of AI ethics is its use in warfare and geopolitical power struggles. AI is becoming integral to military systems, intelligence analysis, and autonomous weapons – raising existential questions about lethal decision-making by machines and the stability of global peace.</p>

<h3 id="autonomous-weapons-killer-robots">Autonomous Weapons (“Killer Robots”)</h3>

<p>One of the biggest debates is over <strong>Lethal Autonomous Weapons Systems (LAWS)</strong> – weapons that can select and engage targets without human intervention. The ethical issues here are immense. First, there’s the question of human control: delegating life-and-death decisions to algorithms arguably crosses a moral line, as machines lack human judgment, empathy, and accountability<sup id="fnref:62"><a href="#fn:62" class="footnote" rel="footnote" role="doc-noteref">62</a></sup><sup id="fnref:63"><a href="#fn:63" class="footnote" rel="footnote" role="doc-noteref">63</a></sup>.</p>

<p>Because of these issues, over 30 countries and numerous NGOs have called for a preemptive ban on killer robots (through campaigns like “Stop Killer Robots”), akin to bans on chemical or biological weapons. In 2015, thousands of AI researchers signed an open letter warning that autonomous weapons could be “the third revolution in warfare” (after gunpowder and nuclear arms)<sup id="fnref:64"><a href="#fn:64" class="footnote" rel="footnote" role="doc-noteref">64</a></sup>.</p>

<h3 id="ai-arms-race-and-geopolitical-tensions">AI Arms Race and Geopolitical Tensions</h3>

<p>We are witnessing an AI arms race in a broader sense: countries pouring resources into military AI for intelligence, cyber warfare, and autonomous systems. This race raises geopolitical ethical questions: will AI make wars more likely by giving some nations confidence in quick, decisive tech-driven victory?</p>

<h2 id="regulatory-outlook">Regulatory Outlook</h2>

<p>The ethical implications of AI span the environmental to the existential. A few clear themes emerge:</p>

<h3 id="transparency-and-accountability">Transparency and Accountability</h3>

<p>Whether it’s training data composition, model decision-making, or AI usage in hiring/policing, openness is critical. We’ve seen that when AI operates as a black box, trust erodes and harms go unmitigated. The <strong>EU’s AI Act</strong> is a significant step in this direction, introducing traceability and oversight requirements<sup id="fnref:65"><a href="#fn:65" class="footnote" rel="footnote" role="doc-noteref">65</a></sup><sup id="fnref:66"><a href="#fn:66" class="footnote" rel="footnote" role="doc-noteref">66</a></sup>.</p>

<h3 id="fairness-and-human-centric-design">Fairness and Human-Centric Design</h3>

<p>AI must be designed and deployed to augment human capabilities and decision-making, not to entrench inequalities or replace human values. The concept of <strong>AI ethics by design</strong> is gaining traction – similar to privacy by design – where equity and fairness checks are baked into the development process from the start.</p>

<h3 id="empowerment-vs-control">Empowerment vs. Control</h3>

<p>There is a fundamental tension between AI’s use to empower users/workers/citizens and its use to control or manipulate them. Ethical AI development leans towards empowerment – using AI to help rather than surveil; giving users more control rather than covertly nudging their behaviour.</p>

<h3 id="global-collaboration-and-norms">Global Collaboration and Norms</h3>

<p>AI’s challenges are global – carbon emitted in one country warms the whole planet; a deepfake in one language can influence another country’s politics; an arms race benefits no nation in the end. Thus, global governance and cooperation are key.</p>

<h3 id="continuous-oversight-and-adaptation">Continuous Oversight and Adaptation</h3>

<p>AI technology evolves quickly. Ethical and regulatory approaches must be agile and updated regularly. One innovative idea is the creation of <strong>AI oversight bodies</strong> – national or regional “AI Agencies” that specialise in monitoring AI developments and advising on policy.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Finally, it’s worth emphasising the human element. AI, for all the talk of autonomy, ultimately reflects human choices – in what objectives we set, what data we feed it, and where we apply it. As AI becomes more powerful, those choices have ever greater impact.</p>

<p>It falls on us – developers, policymakers, business leaders, and society at large – to wield AI in service of human dignity, equity, and prosperity. As the saying goes, with great power comes great responsibility. AI is indeed great power. This article has highlighted some of the responsibilities that come with it.</p>

<p>Navigating the ethical challenges will not be easy, but with informed, global and multidisciplinary engagement, we can ensure AI remains a tool for good – amplifying the best of human ingenuity, not the worst of our biases or greed.</p>

<p><strong>In the end, AI is merely a mirror for human choices—albeit a gigantic, turbo-charged one. With vigilance and humility, we might just keep the mirror cracked but functional rather than shattered.</strong></p>

<hr />

<h2 id="references">References</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>Training GPT-3 used 1,287 MWh, 550 tons CO₂ <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>Data centers water usage for cooling servers <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>Data centers 1.5% of global electricity in 2024 <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p>Doubling by 2030 due to AI growth <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p>Japan annual electricity consumption comparison <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6">
      <p>AI servers ~15% of data center energy <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7">
      <p>Major tech hubs 85% consumption <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:8">
      <p>Inference 90% of AI model lifecycle energy <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:9">
      <p>OpenAI’s Kenyan moderators paid &lt;$2/hour for toxic content labeling <a href="#fnref:9" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:10">
      <p>Psychological trauma reported by moderators <a href="#fnref:10" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:11">
      <p>Mental health damage from graphic content exposure <a href="#fnref:11" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:12">
      <p>Lawsuits over exploitative conditions <a href="#fnref:12" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:13">
      <p>Low pay and inadequate support documentation <a href="#fnref:13" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:14">
      <p>Authors sued OpenAI over books used in training without permission <a href="#fnref:14" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:15">
      <p>Michael Chabon, Jodi Picoult and George R.R. Martin lawsuit <a href="#fnref:15" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:16">
      <p>ChatGPT summarizing and imitating writing styles <a href="#fnref:16" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:17">
      <p>Class actions by authors and publishers <a href="#fnref:17" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:18">
      <p>Visual artists against generative AI companies <a href="#fnref:18" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:19">
      <p>Artists’ class action against Stability AI <a href="#fnref:19" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:20">
      <p>5 billion scraped images in LAION dataset <a href="#fnref:20" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:21">
      <p>Thomson Reuters v ROSS court decision 2025 <a href="#fnref:21" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:22">
      <p>AI training use not fair use ruling <a href="#fnref:22" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:23">
      <p>Search tool repackaging original texts <a href="#fnref:23" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:24">
      <p>Harm to copyright owner’s market <a href="#fnref:24" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:25">
      <p>EU AI Act copyrighted material disclosure <a href="#fnref:25" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:26">
      <p>AI developers transparency requirements <a href="#fnref:26" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:27">
      <p>ChatGPT training data summaries requirement <a href="#fnref:27" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:28">
      <p>OpenAI’s GPT-4 report gave no info on data or training <a href="#fnref:28" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:29">
      <p>Competition and safety concerns cited <a href="#fnref:29" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:30">
      <p>Impossible to evaluate biases without data knowledge <a href="#fnref:30" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:31">
      <p>Amazon’s AI hiring tool penalised “women’s” in resumes <a href="#fnref:31" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:32">
      <p>Tech industry male dominance in training data <a href="#fnref:32" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:33">
      <p>Discrimination against women’s organizations <a href="#fnref:33" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:34">
      <p>Downgrading women’s college graduates <a href="#fnref:34" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:35">
      <p>Amazon engineers unable to guarantee no discrimination <a href="#fnref:35" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:36">
      <p>Project eventually scrapped due to bias issues <a href="#fnref:36" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:37">
      <p>ProPublica COMPAS system investigation findings <a href="#fnref:37" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:38">
      <p>72% Americans prefer AI development slowdown <a href="#fnref:38" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:39">
      <p>Only 8% want AI development to speed up <a href="#fnref:39" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:40">
      <p>Gary Marcus on Big Tech “moral descent” <a href="#fnref:40" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:41">
      <p>Profit over society prioritization <a href="#fnref:41" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:42">
      <p>98% of deepfakes online are pornographic, targeting women <a href="#fnref:42" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:43">
      <p>Facebook’s engagement algorithm boosts divisive content <a href="#fnref:43" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:44">
      <p>Algorithm changes preferentially boost anger reactions <a href="#fnref:44" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:45">
      <p>Arizona mother AI voice cloning scam <a href="#fnref:45" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:46">
      <p>Daughter’s voice perfectly mimicked for kidnapping hoax <a href="#fnref:46" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:47">
      <p>McAfee survey on voice cloning detection <a href="#fnref:47" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:48">
      <p>Europol warning about ChatGPT enabling realistic phishing <a href="#fnref:48" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:49">
      <p>China’s AI surveillance of Uyghurs with facial recognition <a href="#fnref:49" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:50">
      <p>Three wrongful arrests via face recognition in US <a href="#fnref:50" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:51">
      <p>Facial recognition accuracy issues for people of colour <a href="#fnref:51" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:52">
      <p>Robert Williams Detroit wrongful arrest case <a href="#fnref:52" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:53">
      <p>$300k settlement and policy changes <a href="#fnref:53" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:54">
      <p>EU AI Act high-risk employment classification <a href="#fnref:54" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:55">
      <p>Non-discriminatory and transparent requirements <a href="#fnref:55" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:56">
      <p>Amazon’s automated warehouse productivity system <a href="#fnref:56" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:57">
      <p>Real-time worker tracking and metrics <a href="#fnref:57" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:58">
      <p>Automatic warnings and termination notices <a href="#fnref:58" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:59">
      <p>No manager input required for disciplinary action <a href="#fnref:59" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:60">
      <p>300+ employees fired in single warehouse <a href="#fnref:60" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:61">
      <p>10% of staff terminated by automated system <a href="#fnref:61" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:62">
      <p>Autonomous weapons dehumanise decision-making <a href="#fnref:62" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:63">
      <p>Machines lack human judgment and accountability <a href="#fnref:63" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:64">
      <p>2015 open letter warning about autonomous weapons <a href="#fnref:64" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:65">
      <p>EU AI Act traceability requirements <a href="#fnref:65" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:66">
      <p>Oversight and transparency mandates <a href="#fnref:66" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Justin O'Brien</name></author><category term="artificial-intelligence" /><category term="ethics" /><category term="technology" /><category term="ai-ethics" /><category term="machine-learning" /><category term="bias" /><category term="surveillance" /><category term="automation" /><category term="regulation" /><category term="environmental-impact" /><category term="copyright" /><summary type="html"><![CDATA[Artificial intelligence has catapulted from the plaything of graduate students to the digital weather system that now soaks every corner of the economy. The upsides are dazzling; the downsides, well, they're the reason you're reading this article instead of a holiday brochure.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4001/assets/images/posts/2025-07-23-ethics-in-artificial-intelligence/ai-ethics.jpg" /><media:content medium="image" url="http://localhost:4001/assets/images/posts/2025-07-23-ethics-in-artificial-intelligence/ai-ethics.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Why Cant We Be Friends</title><link href="http://localhost:4001/2025/07/20/why-cant-we-be-friends/" rel="alternate" type="text/html" title="Why Cant We Be Friends" /><published>2025-07-20T00:00:00+01:00</published><updated>2025-07-20T00:00:00+01:00</updated><id>http://localhost:4001/2025/07/20/why-cant-we-be-friends</id><content type="html" xml:base="http://localhost:4001/2025/07/20/why-cant-we-be-friends/"><![CDATA[]]></content><author><name>Justin O'Brien</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Rightsizing Rant</title><link href="http://localhost:4001/2025/07/15/rightsizing-rant/" rel="alternate" type="text/html" title="Rightsizing Rant" /><published>2025-07-15T00:00:00+01:00</published><updated>2025-07-15T00:00:00+01:00</updated><id>http://localhost:4001/2025/07/15/rightsizing-rant</id><content type="html" xml:base="http://localhost:4001/2025/07/15/rightsizing-rant/"><![CDATA[]]></content><author><name>Justin O'Brien</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Flatpacks Not Ivory Towers</title><link href="http://localhost:4001/2025/07/10/flatpacks-not-ivory-towers/" rel="alternate" type="text/html" title="Flatpacks Not Ivory Towers" /><published>2025-07-10T00:00:00+01:00</published><updated>2025-07-10T00:00:00+01:00</updated><id>http://localhost:4001/2025/07/10/flatpacks-not-ivory-towers</id><content type="html" xml:base="http://localhost:4001/2025/07/10/flatpacks-not-ivory-towers/"><![CDATA[]]></content><author><name>Justin O'Brien</name></author><summary type="html"><![CDATA[]]></summary></entry></feed>