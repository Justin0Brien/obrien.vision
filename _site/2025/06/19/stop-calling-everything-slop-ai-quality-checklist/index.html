<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Stop Calling Everything 'Slop': Build a Smarter AI Quality Checklist</title>
  
  <!-- Favicon and Touch Icons -->
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  <link rel="apple-touch-icon-precomposed" href="/apple-touch-icon-precomposed.png">
  <link rel="icon" type="image/svg+xml" href="/assets/icons/icon-base.svg">
  <link rel="manifest" href="/site.webmanifest">
  
  <link rel="stylesheet" href="/assets/css/style.css?v=c739fb25fd5bec2b152a31180e9ca930f3873ab7">
  <!--[if lt IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
  <![endif]-->
  <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

</head>
<body class="post-page">
  <div class="wrapper">
    <!-- Main Navigation -->
    <nav class="main-navigation">
      <div class="nav-container">
        <div class="nav-brand">
          <a href="http://0.0.0.0:4000/" class="nav-brand">
            <span class="site-name-primary">obrien</span><span class="site-name-secondary">.vision</span>
          </a>
        </div>
        
        <!-- Mobile menu toggle -->
        <button class="mobile-menu-toggle" aria-label="Toggle navigation menu" aria-expanded="false">
          <span class="hamburger-line"></span>
          <span class="hamburger-line"></span>
          <span class="hamburger-line"></span>
        </button>
        
        <!-- Navigation Menu -->
        <div class="nav-menu">
          <ul class="nav-links">
            
            
              <li class="nav-item">
                
                <a href="/" class="nav-link ">Home</a>
              </li>
            
              <li class="nav-item">
                <span class="nav-sep">|</span>
                <a href="/blog/" class="nav-link ">Blog</a>
              </li>
            
              <li class="nav-item">
                <span class="nav-sep">|</span>
                <a href="/images/" class="nav-link ">Images</a>
              </li>
            
              <li class="nav-item">
                <span class="nav-sep">|</span>
                <a href="/illusions/" class="nav-link ">Illusions</a>
              </li>
            
              <li class="nav-item">
                <span class="nav-sep">|</span>
                <a href="/visualizations/" class="nav-link ">DataViz</a>
              </li>
            
              <li class="nav-item">
                <span class="nav-sep">|</span>
                <a href="/about/" class="nav-link ">About</a>
              </li>
            
              <li class="nav-item">
                <span class="nav-sep">|</span>
                <a href="/contact/" class="nav-link ">Contact</a>
              </li>
            
            <li class="nav-item">
              <button id="theme-toggle" class="theme-toggle-nav" aria-label="Toggle theme">ğŸŒ™</button>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <main>
      <div class="container">
        <article class="post">
  <header class="post-header">
    <h1 class="post-title">Stop Calling Everything 'Slop': Build a Smarter AI Quality Checklist</h1>
    <p class="post-meta">
      <time datetime="2025-06-19T00:00:00+01:00">June 19, 2025</time>
       â€¢ Justin O'Brien
    </p>
    
    <p class="post-categories">
      
        <span class="category">artificial-intelligence</span>
      
        <span class="category">quality-control</span>
      
        <span class="category">content-creation</span>
      
    </p>
    
  </header>

  
  <div class="post-hero">
    <img src="/assets/images/posts/2025-06-19-stop-calling-everything-slop-ai-quality-checklist/jargon-blob-illustration.jpg" alt="Stop Calling Everything 'Slop': Build a Smarter AI Quality Checklist" class="hero-image">
  </div>
  

  <div class="post-content">
    <p><img src="/assets/images/posts/2025-06-19/slop-delve.png" alt="AI Quality Taxonomy Overview" /></p>

<p><em>Originally published June 19, 2025</em></p>

<h2 id="slop-is-sloppy">Slop is Sloppy</h2>

<p>The Generative-AI backlash has coined a new catch-all insult: â€œAI slop.â€ The label began life as internet shorthand for the torrents of low-effort, algorithm-written web pages and uncanny Midjourney pictures that clog our feeds, but it has since mutated into a blanket sneer aimed at almost any machine-assisted work. A close look at the termâ€™s roots shows why the metaphor of â€œslopâ€ is rhetorically powerful yet often intellectually lazy: it conflates genuine creative misfires with otherwise polished writing or imagery that simply stumbles on the last metreâ€”extra fingers here, a mis-dated statistic there. In short, â€œslopâ€ risks obscuring nuance just when we most need clear critical vocabulary.</p>

<h2 id="where-slop-comes-from">Where â€œSlopâ€ Comes From</h2>

<p>Slop began life in late-mediaeval English as a word for a muddy puddle. By the seventeenth century it had slidâ€”appropriatelyâ€”into farm talk for semi-liquid pig feed, and by Victorian times it carried two extra shades of contempt: mass-produced cheap clothing sold in â€œslop-shopsâ€, and sentimental drivel in popular fiction. The sound of the word, rooted in the same Germanic stem as slip and slide, has always suggested something wet, messy and faintly unpleasant.</p>

<p>In 2024 the tech community borrowed the term to label low-effort, machine-generated content: â€œAI slop.â€ The analogy to junk e-mail â€œspamâ€ was irresistibleâ€”and accurate when youâ€™re scrolling past six-fingered celebrity portraits or keyword-stuffed listicles. But using slop for every piece of AI-assisted work is, well, sloppy. A polished image with a stray extra thumb, or an otherwise solid article with a single mis-dated statistic, deserves more precise criticism than a trip to the pig trough.</p>

<h2 id="why-the-metaphor-misfires">Why the Metaphor Misfires</h2>

<p><strong>It Collapses Gradations of Quality</strong> - Not all machine-assisted work is interchangeable mush. Lumping everything together as slop discourages more precise critique.</p>

<p><strong>It Blinds Us to Human Complicity</strong> - Many so-called slop sites are monetised by ordinary publishers chasing ad revenue or engagement metrics, not by the models themselves. Calling the output â€œAI slopâ€ can deflect responsibility from the editors who chose speed over standards.</p>

<p><strong>It Fuels Blanket Scepticism</strong> - The Guardian notes that rising public distrust now leads readers to assume authentic flood photos are <a href="https://www.theguardian.com/commentisfree/2024/nov/09/the-images-of-spains-floods-werent-created-by-ai-the-trouble-is-people-think-they-were">deepfakes</a>, hampering disaster response. Over-using the epithet slop risks a boy-who-cried-wolf effect in which all digital media are suspect and genuine warnings are ignored.</p>

<p>If every AI-touched work is dismissed as pigswill, we lose the ability to judge craft, intention and risk on their merits. Better to reserve slop for genuine sludgeâ€”and enrich our critical toolkit with vocabulary that discriminates between a puddle and a merely muddy boot-print.</p>

<p>Below is a working taxonomy I use, synthesised from sources in disparate domains. It groups errors into six high-level families and gives each sub-type a short codeâ€”handy for tagging documents or briefing reviewers.</p>

<h2 id="the-six-families-of-ai-quality-issues">The Six Families of AI Quality Issues</h2>

<ol>
  <li>
    <p><strong>Synthetic Truth Failures</strong> â€“ When the modelâ€™s facts are wrong. That includes outright hallucinations, out-of-date statements, fabricated citations, faulty numbers, mis-quoted sources and other inventions that undermine factual reliability.</p>
  </li>
  <li>
    <p><strong>Semantic &amp; Structural Incoherence</strong> â€“ The answer may be factually fine, yet the writing itself is muddled: contradictions, run-on repetition, abrupt truncations, broken formatting, off-topic rambles, word-salad syntax, persona drift or verbose filler.</p>
  </li>
  <li>
    <p><strong>Aesthetic Anomalies</strong> â€“ Glitches you can see or hear: extra fingers in an image, impossible camera angles, jittery video frames, lip-sync slips, robotic speech or buzz-phrase-laden prose that instantly signals â€œthis was generatedâ€.</p>
  </li>
  <li>
    <p><strong>Ethical &amp; Societal Harm</strong> â€“ Content that causes social damage: biased or stereotyped depictions, hate speech, deep-fake misinformation, unlicensed use of copyrighted material, or mass-produced spam that clogs information channels.</p>
  </li>
  <li>
    <p><strong>Security &amp; Privacy Breaches</strong> â€“ Attacks or accidents that expose data or create system risk, such as prompt-injection exploits, leakage of private training data, or AI-generated code that ships with hidden vulnerabilities.</p>
  </li>
  <li>
    <p><strong>Alignment &amp; Control Deviations</strong> â€“ Moments when the model ignores its safety rails: providing disallowed instructions, delivering over-confident claims with no basis, or doling out definitive medical/legal advice it was never authorised to give.</p>
  </li>
</ol>

<p><img src="/assets/images/posts/2025-06-19/jargon-blob-illustration.jpg" alt="The Jargon Blob says &quot;Synergy! Optimize! Paradigm Shift! Leverage!" /></p>

<h2 id="1--synthetic-truth-failures">1 â€“ Synthetic Truth Failures</h2>

<p><em>When the model gets the facts wrong</em></p>

<p><strong>Fabrication</strong> â€“ Invents people, events or facts (â€œhallucinationsâ€). âš–ï¸ <em>A New York lawyer cited six non-existent court decisions fabricated by ChatGPT</em> (<a href="https://www.legaldive.com/news/chatgpt-fake-legal-cases-generative-ai-hallucinations/651557/">LegalDive</a>)</p>

<p><strong>Temporal drift</strong> â€“ Gives information that used to be true but is now outdated. ğŸ•°ï¸ <em>Some LLMs still name outdated office-holders after their training cut-off</em> (<a href="https://www.theguardian.com/business/2025/jun/15/policymakers-who-think-ai-can-help-rescue-flagging-uk-economy-should-take-heed">Guardian</a>)</p>

<p><strong>Confabulated citation</strong> â€“ Cites journals, URLs or court cases that do not exist. ğŸ“š <em>Users requesting niche academic references receive fictitious DOIs and broken links</em> (<a href="https://www.theguardian.com/business/2025/jun/15/policymakers-who-think-ai-can-help-rescue-flagging-uk-economy-should-take-heed">same Guardian investigation</a>)</p>

<p><strong>Numeric mis-calculation</strong> â€“ Bungles sums, exchange rates or unit conversions. ğŸ§® <em>GPT-3.5 stumbles on multi-step arithmetic problems</em> (<a href="https://www.theguardian.com/business/2025/jun/15/policymakers-who-think-ai-can-help-rescue-flagging-uk-economy-should-take-heed">Guardian analysis</a>)</p>

<p><strong>Quote / attribution error</strong> â€“ Puts real words in the wrong mouth or cites the wrong source. ğŸ—£ï¸ <em>ChatGPT mis-credited 153 of 200 press quotes, including an Orlando Sentinel letter attributed to Time</em> (<a href="https://www.cjr.org/tow_center/how-chatgpt-misrepresents-publisher-content.php">CJR</a>); <em>fake court citations also turning up in filings</em> (<a href="https://www.businessinsider.com/increasing-ai-hallucinations-fake-citations-court-records-data-2025-5">Business Insider</a>)</p>

<p><strong>Entity conflation</strong> â€“ Melds details from two or more people into one biography. ğŸªª <em>ChatGPT repeatedly listed privacy activist Max Schrems with the wrong birth date, prompting a NOYB complaint</em> (<a href="https://timesofindia.indiatimes.com/world/rest-of-world/chatgpt-faces-plaint-in-austria-for-hallucinating-wrong-answers/articleshow/109704321.cms">Times of India</a>)</p>

<p><strong>Biographical defamation</strong> â€“ States reputationally damaging falsehoods about a real person. âš ï¸ <em>The model alleged an Australian mayor had served prison time; he is now suing for defamation</em> (<a href="https://www.reuters.com/technology/australian-mayor-readies-worlds-first-defamation-lawsuit-over-chatgpt-content-2023-04-05/">Reuters</a>)</p>

<p><strong>Geospatial misplacement</strong> â€“ Pins an event to the wrong location or mis-labels landmarks. ğŸ“ <em>AI â€œphotosâ€ showed a flooded Disney World during Hurricane Milton; Reuters debunked them</em> (<a href="https://www.reuters.com/fact-check/ai-images-flooded-disney-world-spread-online-2024-10-15/">Reuters</a>) â€“ <em>genuine Spanish flood images were also dismissed as AI fakes</em> (<a href="https://www.theguardian.com/commentisfree/2024/nov/09/the-images-of-spains-floods-werent-created-by-ai-the-trouble-is-people-think-they-were">Guardian</a>)</p>

<p><strong>Statistical phantom</strong> â€“ Invents survey data, market shares or PDFs to match. ğŸ“Š <em>Asked for Polish cloud-adoption figures, ChatGPT produced non-existent Deloitte reports and broken links</em> (<a href="https://medium.com/@agata.cupriak/why-is-chatgpt-making-up-facts-and-how-to-deal-with-that-57b504dd28">Medium</a>); <em>MIT Sloan warns of widespread â€œphantom datasetsâ€</em> (<a href="https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/">MIT Sloan EdTech</a>)</p>

<p><strong>Why it matters:</strong> Synthetic truth failures undermine credibility outright. Some even carry legal risk.</p>

<h2 id="2--semantic--structural-incoherence">2 â€“ Semantic &amp; Structural Incoherence</h2>

<p><em>When the prose sounds offâ€”even if the facts are technically correct</em></p>

<p><strong>Logical contradiction</strong> â€“ Claims two incompatible facts in the same answer. ğŸ”„ <em>ChatGPT once described a jacket as both â€œcompletely waterproofâ€ and â€œnot water-resistantâ€ in a single paragraph</em> (<a href="https://medium.com/@mbonsign/improving-large-language-models-handling-of-contradictions-fostering-epistemic-humility-629fca6abcf0">Medium</a>)</p>

<p><strong>Run-on repetition</strong> â€“ Loops favourite phrases (â€œAs an AI language modelâ€¦â€) or drifts into copy-paste mode. ğŸ” <em>A Nature study shows models fed on their own output spiral into repetitive â€œmodel-collapseâ€ loops</em> (<a href="https://www.nature.com/articles/s41586-024-07566-y">Nature</a>)</p>

<p><strong>Truncation</strong> â€“ Cuts off mid-sentence or drops a heading when the context window overflows. âœ‚ï¸ <em>Devs report ChatGPT abruptly ending replies once it hits token limits</em> (<a href="https://www.o8.agency/blog/ai/advanced-chatgpt-context-windows-and-prompt-engineering">o8 Agency blog</a>)</p>

<p><strong>Formatting breakage</strong> â€“ Outputs code or tables that will not compile or render. ğŸ§© <em>An arXiv audit found 32% of GitHub Copilot snippets failed to compile across four languages</em> (<a href="https://arxiv.org/html/2310.02059v1">arXiv</a>)</p>

<p><strong>Irrelevant reply</strong> â€“ Answers a different question altogether. â“ <em>The Dr3 benchmark records GPT-4 replying â€œBarack Obamaâ€ to â€œIn which year was David Beckhamâ€™s wife born?â€</em> (<a href="https://arxiv.org/html/2403.12393v1">arXiv</a>)</p>

<p><strong>Word-salad</strong> â€“ Produces grammatically tangled, semantically empty text. ğŸ¥— <em>Researchers scored frontier models on a â€œgibberish scaleâ€, flagging bursts of incoherent word-salad</em> (<a href="https://arxiv.org/html/2410.15234v3">arXiv</a>)</p>

<p><strong>Topic drift</strong> â€“ Wanders off into an unrelated subject as the chat grows. ğŸ§­ <em>A 2025 study on â€œgoal driftâ€ shows agents veer off task after long context interactions</em> (<a href="https://arxiv.org/html/2505.02709v1">arXiv</a>)</p>

<p><strong>Persona drift</strong> â€“ Forgets its assigned role or leaks hidden instructions. ğŸ­ <em>â€œMeasuring Persona Driftâ€ tests found consistency collapsing over multi-session dialogues</em> (<a href="https://arxiv.org/html/2402.10962v1">arXiv</a>)</p>

<p><strong>Verbosity compensation</strong> â€“ Pads answers with florid filler to mask uncertainty. ğŸ“œ <em>The first paper on Verbosity Compensation shows LLMs grow wordier when unsure</em> (<a href="https://openreview.net/forum?id=l49uZcEIcq">OpenReview</a>)</p>

<p><strong>Why it matters:</strong> Sloppy structure confuses readers and saps trustâ€”even if nothing is factually wrong.</p>

<h2 id="3--aesthetic-anomalies">3 â€“ Aesthetic Anomalies</h2>

<p><em>The look or sound of the output gives the game away</em></p>

<p><strong>Visual artefact</strong> â€“ Extra fingers, fused limbs in a still image. ğŸ–ï¸ <em>AI-generated portraits often show hands with nine fingers or digits growing from palms</em> (<a href="https://www.britannica.com/topic/Why-does-AI-art-screw-up-hands-2230501">Britannica</a>)</p>

<p><strong>Phantom perspective</strong> â€“ Impossible shadows or camera angles. ğŸŒ€ <em>AI images may place staircases that run both up and down at once, a classic perspective giveaway</em> (<a href="https://insight.kellogg.northwestern.edu/article/ai-photos-identification">Kellogg Insight</a>)</p>

<p><strong>Stilted writing style</strong> â€“ Buzz-phrase-ridden corporate waffle. ğŸ“ <em>Cover-letters packed with â€œleveraging data-driven insightsâ€ scream ChatGPT-draft</em> (<a href="https://medium.com/learning-data/words-and-phrases-that-make-it-obvious-you-used-chatgpt-2ba374033ac6">Medium</a>)</p>

<p><strong>Motion artefact</strong> â€“ Limbs rotate 360Â° in video. ğŸ¥ <em>Runway Gen-2 demo clips show wrists spinning unrealistically mid-move</em> (<a href="https://www.youtube.com/watch?v=vezJXJGQMoY">YouTube</a>)</p>

<p><strong>Temporal inconsistency</strong> â€“ Objects morph between frames. â±ï¸ <em>The UniCtrl paper calls such cross-frame drift the â€œcentral unsolved issueâ€ in text-to-video</em> (<a href="https://arxiv.org/abs/2403.02332">arXiv</a>)</p>

<p><strong>Frame ghosting</strong> â€“ Echo silhouettes after frame interpolation. ğŸ‘» <em>Topaz Video AI users report spectral duplicates around moving subjects</em> (<a href="https://community.topazlabs.com/t/frame-interpolation-apollo-makes-some-duplicate-frames/57367">Topaz forum</a>)</p>

<p><strong>Limb distortion</strong> â€“ Body parts vanish or multiply. ğŸ’ª <em>An anatomy-audit found â€œproliferated limbs and missing fingersâ€ rife in T2I datasets</em> (<a href="https://arxiv.org/html/2503.00811v1">arXiv</a>)</p>

<p><strong>Lip-sync slip</strong> â€“ Mouth movement out of time with speech. ğŸ‘„ <em>Berkeleyâ€™s LIPINC detector spots millisecond-level audio-video mismatches in deepfakes</em> (<a href="https://farid.berkeley.edu/downloads/publications/cvprw24c.pdf">PDF</a>)</p>

<p><strong>Gesture drift</strong> â€“ Avatar repeats an awkward shrug. ğŸ¤– <em>Synthesia avatars are criticised for stiff, looping body-language</em> (<a href="https://www.argil.ai/blog/avatar-gestures-in-synthesia-a-complete-guide-to-natural-body-language">Argil AI</a>)</p>

<p><strong>Flat voice prosody</strong> â€“ Monotone, robotic cadence. ğŸ”ˆ <em>Waylineâ€™s UX blog flags flat prosody as a top engagement killer in TTS output</em> (<a href="https://www.wayline.io/blog/imperfect-ai-voice-engagement">Wayline</a>)</p>

<p><strong>Prosodic pathology</strong> â€“ Stress patterns that feel â€œoffâ€. ğŸ—£ï¸ <em>Deepgram explains how monotone or misplaced emphasis reduces naturalness</em> (<a href="https://deepgram.com/learn/text-to-speech-ai">Deepgram</a>)</p>

<p><strong>Textural inconsistency</strong> â€“ Fabrics or grass flicker frame-to-frame. ğŸŒ¾ <em>The VideoJAM paper links â€œtexture flickerâ€ to weak appearance-motion coupling</em> (<a href="https://arxiv.org/abs/2502.02492">arXiv</a>)</p>

<p><strong>Perspective roulette</strong> â€“ Camera jumps to an impossible position mid-shot. ğŸ¥ <em>Researchers catalogue perspective flips as a common diffusion-model failure</em> (<a href="https://arxiv.org/html/2304.06470v6">arXiv</a>)</p>

<p><strong>Why it matters:</strong> Aesthetic glitches are reliable tells for deepfakes and signal that visual quality controlâ€”not another fact-checkâ€”is the urgent next step.</p>

<h2 id="4--ethical--societal-harm">4 â€“ Ethical &amp; Societal Harm</h2>

<p><em>When the content hurts people or the public sphere</em></p>

<p><strong>Bias &amp; stereotyping</strong> â€“ Over-represents one demographic as â€œdefaultâ€. ğŸŒ <em>Stable Diffusion routinely produced light-skinned male faces even for neutral prompts about â€œa personâ€</em> (<a href="https://www.washington.edu/news/2023/11/29/ai-image-generator-stable-diffusion-perpetuates-racial-and-gendered-stereotypes-bias/">UW study</a>)</p>

<p><strong>Toxic language</strong> â€“ Hate, harassment or slurs. ğŸ’¬ <em>Microsoftâ€™s Tay chatbot spiralled into racist tweets within 24 hours of launch</em> (<a href="https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/">Microsoft blog</a>)</p>

<p><strong>Misinformation &amp; deepfakes</strong> â€“ Fake news photos, bogus quotes. ğŸ“° <em>AI â€œphotosâ€ of a flooded Disney World during Hurricane Milton went viral before Reuters debunked them</em> (<a href="https://www.reuters.com/fact-check/ai-images-flooded-disney-world-spread-online-2024-10-15/">Reuters</a>)</p>

<p><strong>Copyright &amp; plagiarism</strong> â€“ Outputs protected material verbatim. Â©ï¸ <em>Getty Images is suing Stability AI for scraping more than 12 million photos to train Stable Diffusion</em> (<a href="https://www.reuters.com/legal/getty-images-lawsuit-says-stability-ai-misused-photos-train-ai-2023-02-06/">Reuters</a>)</p>

<p><strong>Spam scale</strong> â€“ Thousands of low-value pages clogging the web. ğŸ—‘ï¸ <em>NewsGuard is tracking 1,271 AI-generated â€œnewsâ€ sites with minimal human oversight</em> (<a href="https://www.newsguardtech.com/special-reports/ai-tracking-center">NewsGuard</a>)</p>

<p><strong>Why it matters:</strong> Ethical failures crop up in corrections columns, defamation suits and copyright trialsâ€”real-world harm that goes far beyond a mere factual slip-up.</p>

<h2 id="5--security--privacy-breaches">5 â€“ Security &amp; Privacy Breaches</h2>

<p><em>Attacks or accidents that expose data or users</em></p>

<p><strong>Prompt injection</strong> â€“ Attacker hijacks instructions or leaks hidden text. ğŸ›¡ï¸ <em>Industry testing found prompt-injection success rates above 50% across leading LLMs</em> (<a href="https://www.paloaltonetworks.com/cyberpedia/what-is-a-prompt-injection-attack">Palo Alto Networks</a>)</p>

<p><strong>Data leakage</strong> â€“ Private training data or user info spills out. ğŸ”“ <em>A March 2023 bug let some ChatGPT users view othersâ€™ chat titles and billing details</em> (<a href="https://www.reuters.com/technology/chatgpt-owner-openai-fixes-significant-issue-exposing-user-chat-titles-2023-03-22/">Reuters</a>)</p>

<p><strong>Code vulnerability</strong> â€“ Generated code hides an exploitable flaw. ğŸ <em>An arXiv audit showed 32% of Copilotâ€™s Python snippets carried security issues</em> (<a href="https://arxiv.org/html/2310.02059v1">arXiv</a>)</p>

<p><strong>Why it matters:</strong> Security failures incur regulatory fines, reputational damage and ransomware riskâ€”far costlier than a simple typo.</p>

<h2 id="6--alignment--control-deviations">6 â€“ Alignment &amp; Control Deviations</h2>

<p><em>The model ignores or subverts its guardrails</em></p>

<p><strong>Guardrail bypass</strong> â€“ Supplies disallowed instructions (e.g., weapon guides). ğŸ’£ <em>Users tricked Discordâ€™s Clyde chatbot into giving step-by-step recipes for napalm and meth</em> (<a href="https://techcrunch.com/2023/04/20/jailbreak-tricks-discords-new-chatbot-into-sharing-napalm-and-meth-instructions/">TechCrunch</a>)</p>

<p><strong>Over-confidence</strong> â€“ States a low-probability claim as absolute fact. ğŸ“¢ <em>ChatGPT confidently cited non-existent judicial precedents in a U.S. legal brief, fooling the lawyer who filed it</em> (<a href="https://hai.stanford.edu/news/hallucinating-law-legal-mistakes-large-language-models-are-pervasive">Stanford HAI</a>)</p>

<p><strong>Speculative advice</strong> â€“ Hands out medical or legal diagnoses it should not. ğŸ©º <em>A Stanford study found AI chatbots dispensing inappropriate mental-health guidance and validating delusions in therapy-style chats</em> (<a href="https://www.sfgate.com/tech/article/stanford-researchers-chatgpt-bad-therapist-20383990.php">SFGate</a>)</p>

<p><strong>Why it matters:</strong> Alignment failures breach safety promises, expose users to real-world harm and heighten regulatory scrutiny.</p>

<hr />

<h2 id="closing-thought">Closing Thought</h2>

<p>If â€œAI slopâ€ is a lazy label, our response should be the opposite: attentive, specific and proportionate. Naming the precise failureâ€”whether itâ€™s a phantom statistic or a jailbreak that spills private dataâ€”gives designers a target to fix and audiences a reason to keep reading. The next time an algorithm slips, letâ€™s reach for the right code in the taxonomy instead of the nearest trough: clearer language is the first step towards cleaner machine-made work.</p>

<hr />

<p><em>Have you encountered specific AI quality issues in your work? Which categories from this taxonomy do you find most useful for evaluation? <a href="/contact/">Share your thoughts</a> or discuss this framework with your team.</em></p>

  </div>

  
  <footer class="post-footer">
    <div class="post-tags">
      <strong>Tags:</strong>
      
        <span class="tag">ai-ethics</span>
      
        <span class="tag">machine-learning</span>
      
        <span class="tag">content-quality</span>
      
        <span class="tag">ai-criticism</span>
      
        <span class="tag">taxonomy</span>
      
    </div>
  </footer>
  
</article>

<style>
.post {
  max-width: none;
}

.post-header {
  margin-bottom: 2rem;
  border-bottom: 1px solid #e5e5e5;
  padding-bottom: 1rem;
}

.post-title {
  margin: 0 0 0.5rem 0;
  font-size: 2.2rem;
  line-height: 1.2;
}

.post-meta {
  color: #666;
  font-size: 0.9rem;
  margin: 0.5rem 0;
}

.post-categories {
  margin: 0.5rem 0;
}

.category {
  background: #f0f0f0;
  padding: 0.2rem 0.5rem;
  border-radius: 3px;
  font-size: 0.8rem;
  margin-right: 0.5rem;
  color: #555;
}

.post-hero {
  margin: 1.5rem 0;
  text-align: center;
}

.hero-image {
  max-width: 100%;
  height: auto;
  border-radius: 8px;
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}

.post-content {
  line-height: 1.6;
  margin: 2rem 0;
}

.post-content h2 {
  margin-top: 2rem;
  margin-bottom: 1rem;
  color: #333;
}

.post-content h3 {
  margin-top: 1.5rem;
  margin-bottom: 0.8rem;
  color: #444;
}

.post-content p {
  margin-bottom: 1rem;
}

.post-content blockquote {
  border-left: 4px solid #ddd;
  margin: 1.5rem 0;
  padding-left: 1rem;
  font-style: italic;
  color: #666;
}

.post-footer {
  margin-top: 2rem;
  padding-top: 1rem;
  border-top: 1px solid #e5e5e5;
}

.post-tags {
  margin: 1rem 0;
}

.tag {
  background: #e8f4f8;
  color: #2c3e50;
  padding: 0.2rem 0.5rem;
  border-radius: 3px;
  font-size: 0.8rem;
  margin-right: 0.5rem;
  display: inline-block;
}

/* Dark mode styles */
[data-theme="dark"] .post-header {
  border-bottom-color: #444;
}

[data-theme="dark"] .post-meta {
  color: #ccc;
}

[data-theme="dark"] .category {
  background: #444;
  color: #ddd;
}

[data-theme="dark"] .post-content h2,
[data-theme="dark"] .post-content h3 {
  color: #f0f0f0;
}

[data-theme="dark"] .post-content blockquote {
  border-left-color: #666;
  color: #bbb;
}

[data-theme="dark"] .post-footer {
  border-top-color: #444;
}

[data-theme="dark"] .tag {
  background: #2c3e50;
  color: #ecf0f1;
}
</style>

      </div>
    </main>

    <footer>
      <div class="container">
        <div class="footer-links">
          
          
            <a href="/privacy/">Privacy Policy</a>
            <span class="footer-sep">|</span>
          
            <a href="/terms/">Terms of Service</a>
            <span class="footer-sep">|</span>
          
            <a href="/feed.xml">RSS Feed</a>
            
          
        </div>
        <p class="footer-brand">&copy; 2025 <span class="site-name-secondary">Justin O'Brien</span>. All rights reserved.</p>
        <p>Data visualization and analysis insights for modern employment dynamics.</p>
      </div>
    </footer>
  </div>
  <script src="/assets/js/theme-toggle.js"></script>
  <script src="/assets/js/navigation.js"></script>
</body>
</html>